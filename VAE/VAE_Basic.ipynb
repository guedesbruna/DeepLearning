{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a02ebecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "import os\n",
    "from torchvision import datasets, transforms\n",
    "from torch import optim, nn, unsqueeze\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor, Lambda, Compose\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn.functional as F\n",
    "import torchvision.utils as vutils\n",
    "import torch.nn as nn\n",
    "from torch.distributions.log_normal import LogNormal\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa93991e",
   "metadata": {},
   "source": [
    "# VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c29fda",
   "metadata": {},
   "source": [
    "### FID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f76dd8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy\n",
    "# from numpy import cov\n",
    "# from numpy import trace\n",
    "# from numpy import iscomplexobj\n",
    "# from numpy import asarray\n",
    "# from numpy.random import shuffle\n",
    "# from scipy.linalg import sqrtm\n",
    "# from keras.applications.inception_v3 import InceptionV3\n",
    "# from keras.applications.inception_v3 import preprocess_input\n",
    "# from keras.datasets.mnist import load_data\n",
    "# from skimage.transform import resize\n",
    "# from torchvision.datasets import SVHN\n",
    " \n",
    "# # scale an array of images to a new size\n",
    "# def scale_images(images, new_shape):\n",
    "# \timages_list = list()\n",
    "# \tfor image in images:\n",
    "# \t\t# resize with nearest neighbor interpolation\n",
    "# \t\tnew_image = resize(image, new_shape, 0)\n",
    "# \t\t# store\n",
    "# \t\timages_list.append(new_image)\n",
    "# \treturn asarray(images_list)\n",
    " \n",
    "# # calculate frechet inception distance\n",
    "# def calculate_fid(model, images1, images2):\n",
    "# \t# calculate activations\n",
    "# \tact1 = model.predict(images1)\n",
    "# \tact2 = model.predict(images2)\n",
    "# \t# calculate mean and covariance statistics\n",
    "# \tmu1, sigma1 = act1.mean(axis=0), cov(act1, rowvar=False)\n",
    "# \tmu2, sigma2 = act2.mean(axis=0), cov(act2, rowvar=False)\n",
    "# \t# calculate sum squared difference between means\n",
    "# \tssdiff = numpy.sum((mu1 - mu2)**2.0)\n",
    "# \t# calculate sqrt of product between cov\n",
    "# \tcovmean = sqrtm(sigma1.dot(sigma2))\n",
    "# \t# check and correct imaginary numbers from sqrt\n",
    "# \tif iscomplexobj(covmean):\n",
    "# \t\tcovmean = covmean.real\n",
    "# \t# calculate score\n",
    "# \tfid = ssdiff + trace(sigma1 + sigma2 - 2.0 * covmean)\n",
    "# \treturn fid\n",
    " \n",
    "# # prepare the inception v3 model\n",
    "# model = InceptionV3(include_top=False, pooling='avg', input_shape=(299,299,3))\n",
    "# # load cifar10 images\n",
    "# (images1, _), (images2, _) = SVHN.load_data()\n",
    "# shuffle(images1)\n",
    "# images1 = images1[:10000]\n",
    "# print('Loaded', images1.shape, images2.shape)\n",
    "# # convert integer to floating point values\n",
    "# images1 = images1.astype('float32')\n",
    "# images2 = images2.astype('float32')\n",
    "# # resize images\n",
    "# images1 = scale_images(images1, (299,299,3))\n",
    "# images2 = scale_images(images2, (299,299,3))\n",
    "# print('Scaled', images1.shape, images2.shape)\n",
    "# # pre-process images\n",
    "# images1 = preprocess_input(images1)\n",
    "# images2 = preprocess_input(images2)\n",
    "# # calculate fid\n",
    "# fid = calculate_fid(model, images1, images2)\n",
    "# print('FID: %.3f' % fid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a004e216",
   "metadata": {},
   "source": [
    "## MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f50bce10",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.1307,), (0.3081,))]) \n",
    "# transform = transforms.Compose([transforms.Resize((32, 32)), \n",
    "#                                 transforms.ToTensor(),\n",
    "#                                 transforms.Lambda(lambda x: x.repeat(3,1,1)),\n",
    "#                                 transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "#load in full train set\n",
    "trainsetfull = torchvision.datasets.MNIST(root='./data/mnist', train=True, download=True, transform=transform)\n",
    "# type(trainsetfull)\n",
    "\n",
    "# data loader for final run \n",
    "trainfullloader = torch.utils.data.DataLoader(trainsetfull, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "#split the set \n",
    "trainset, valset = torch.utils.data.random_split(trainsetfull, [55000, 5000])\n",
    "#load in test set\n",
    "testset = torchvision.datasets.MNIST(root='./data/mnist', train=False, transform=transform,download=True)\n",
    "\n",
    "\n",
    "# data loader for training\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE,shuffle=True, num_workers=2)\n",
    "# data loader for validation\n",
    "valiloader = torch.utils.data.DataLoader(valset, batch_size=BATCH_SIZE,shuffle=True, num_workers=2)\n",
    "# data loader for testing\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE,shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c51cb8",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4fb9e5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FROM SLIDES\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, D, M):\n",
    "        super(VAE, self).__init__()\n",
    "        self.D = D\n",
    "        self.M = M\n",
    "\n",
    "        self.enc1 = nn.Linear(in_features=self.D, out_features=300)\n",
    "        self.enc2 = nn.Linear(in_features=300, out_features=self.M*2)\n",
    "\n",
    "        self.dec1 = nn.Linear(in_features=self.M, out_features=300)\n",
    "        self.dec2 = nn.Linear(in_features=300, out_features=self.D)\n",
    "\n",
    "    def reparameterize(self, mu, log_std): \n",
    "        std = torch.exp(log_std)\n",
    "        eps = torch.randn_like(std)\n",
    "        z = mu + (eps * std)\n",
    "        return z\n",
    "\n",
    "    def forward(self, x): # encoder\n",
    "        # x = nn.functional.relu(self.enc1(x))\n",
    "        # x = self.enc2(x).view(-1, 2, self.M)\n",
    "        \n",
    "        # encoder\n",
    "        x = self.enc1(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.enc2(x).view(-1, 2, self.M)\n",
    "        \n",
    "        # get mean and log-std\n",
    "        mu = x[:, 0, :]\n",
    "        log_std = x[:, 1, :]\n",
    "        \n",
    "        # reparameterization\n",
    "        z = self.reparameterize(mu, log_std)\n",
    "\n",
    "        # # decoder\n",
    "        # x_hat = nn.functional.relu(self.dec1(z)) \n",
    "        # x_hat = self.dec2(x)\n",
    "        # return x_hat, mu, log_std\n",
    "\n",
    "        # decoder\n",
    "        x_hat = nn.functional.relu(self.dec1(z))\n",
    "        x_hat = torch.sigmoid(self.dec2(x_hat))\n",
    "        return x_hat, mu, z, log_std\n",
    "\n",
    "    def generate(self, z):\n",
    "        x_hat = nn.functional.relu(self.dec1(z))\n",
    "        x_hat = torch.sigmoid(self.dec2(x_hat))\n",
    "        return x_hat\n",
    "\n",
    "    def elbo(self, x, x_hat, z, mu, log_std): \n",
    "        # reconstruction error\n",
    "        # RE = nn.loss.mse(x, x_hat)\n",
    "\n",
    "        RE = F.binary_cross_entropy(x_hat, x)\n",
    "\n",
    "        # kl-regularization\n",
    "        # We assume here that log_normal is implemented\n",
    "        # KL = LogNormal(z, mu, log_std) - LogNormal(z, 0, 1)\n",
    "\n",
    "        KL = -0.5 * torch.sum(1 + log_std - mu.pow(2) - log_std.exp())\n",
    "        KL /= (784 * x_hat.size(0))\n",
    "\n",
    "        # REMEMBER! We maximize ELBO, but optimizers minimize. # Therefore, we need to take the negative sign!\n",
    "        return -(RE - KL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "72a1777b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, dataloader, optimizer):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for i, data in enumerate(dataloader):\n",
    "\n",
    "        data = data[0].to(device)\n",
    "        data = data.view(data.size(0),-1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        data_hat, mu,z, log_std = model(data)\n",
    "        loss = model.elbo(x = data, x_hat = data_hat,z=z, mu = mu, log_std = log_std)\n",
    "        running_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    train_loss = running_loss/len(dataloader.dataset)\n",
    "    return train_loss\n",
    "\n",
    "    #from google.colab import files\n",
    "def validate(model, valdataloader, epoch):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(valdataloader):\n",
    "            #data, _ = data\n",
    "            data = data[0].to(device)\n",
    "            data = data.view(data.size(0),-1)\n",
    "            data_hat, mu, z, log_std = model(data)\n",
    "            loss = model.elbo(data, data_hat,z, mu, log_std)\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            if (epoch%10 == 0) and (i == len(valiloader)-1):\n",
    "                # save the last 8 samples input and output of every 10th epoch\n",
    "                num_rows = 8\n",
    "                both = torch.cat((data.view(len(data), 1, 28, 28)[:8], \n",
    "                                  data_hat.view(len(data), 1, 28, 28)[:8]))\n",
    "                # both = torch.cat((data.view(len(data), 3, 32, 32)[:8], \n",
    "                #                   data_hat.view(len(data), 3, 32, 32)[:8]))\n",
    "                torchvision.utils.save_image(both.cpu(), f\"./output{epoch}.png\", nrow=num_rows)\n",
    "    \n",
    "    #val_loss = running_loss/len(valiloader.dataset)\n",
    "    return running_loss/len(valiloader.dataset)\n",
    "\n",
    "def train(model, trainloader, valiloader, optimizer, epochs):\n",
    "  train_loss, val_loss = [], []\n",
    "\n",
    "  for epoch in range(epochs):\n",
    "      print(f\"Epoch {epoch+1} of {epochs}\")\n",
    "      train_epoch_loss = fit(model, trainloader, optimizer)\n",
    "      val_epoch_loss = validate(model, valiloader, epoch)\n",
    "      train_loss.append(train_epoch_loss)\n",
    "      val_loss.append(val_epoch_loss)\n",
    "      print(f\"Train Loss: {train_epoch_loss:.4f}\")\n",
    "      print(f\"Val Loss: {val_epoch_loss:.4f}\")\n",
    "\n",
    "  return model, train_loss, val_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "29d484b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 50\n",
      "Train Loss: -1.8039\n",
      "Val Loss: -1.9352\n",
      "Epoch 2 of 50\n",
      "Train Loss: -1.9399\n",
      "Val Loss: -1.9834\n",
      "Epoch 3 of 50\n",
      "Train Loss: -1.9812\n",
      "Val Loss: -2.0166\n",
      "Epoch 4 of 50\n",
      "Train Loss: -2.0096\n",
      "Val Loss: -2.0477\n",
      "Epoch 5 of 50\n",
      "Train Loss: -2.0332\n",
      "Val Loss: -2.0590\n",
      "Epoch 6 of 50\n",
      "Train Loss: -2.0413\n",
      "Val Loss: -2.0668\n",
      "Epoch 7 of 50\n",
      "Train Loss: -2.0460\n",
      "Val Loss: -2.0696\n",
      "Epoch 8 of 50\n",
      "Train Loss: -2.0489\n",
      "Val Loss: -2.0716\n",
      "Epoch 9 of 50\n",
      "Train Loss: -2.0507\n",
      "Val Loss: -2.0747\n",
      "Epoch 10 of 50\n",
      "Train Loss: -2.0521\n",
      "Val Loss: -2.0735\n",
      "Epoch 11 of 50\n",
      "Train Loss: -2.0533\n",
      "Val Loss: -2.0751\n",
      "Epoch 12 of 50\n",
      "Train Loss: -2.0539\n",
      "Val Loss: -2.0761\n",
      "Epoch 13 of 50\n",
      "Train Loss: -2.0550\n",
      "Val Loss: -2.0773\n",
      "Epoch 14 of 50\n",
      "Train Loss: -2.0557\n",
      "Val Loss: -2.0753\n",
      "Epoch 15 of 50\n",
      "Train Loss: -2.0561\n",
      "Val Loss: -2.0779\n",
      "Epoch 16 of 50\n",
      "Train Loss: -2.0567\n",
      "Val Loss: -2.0776\n",
      "Epoch 17 of 50\n",
      "Train Loss: -2.0571\n",
      "Val Loss: -2.0786\n",
      "Epoch 18 of 50\n",
      "Train Loss: -2.0572\n",
      "Val Loss: -2.0785\n",
      "Epoch 19 of 50\n",
      "Train Loss: -2.0576\n",
      "Val Loss: -2.0792\n",
      "Epoch 20 of 50\n",
      "Train Loss: -2.0578\n",
      "Val Loss: -2.0772\n",
      "Epoch 21 of 50\n",
      "Train Loss: -2.0580\n",
      "Val Loss: -2.0757\n",
      "Epoch 22 of 50\n",
      "Train Loss: -2.0581\n",
      "Val Loss: -2.0810\n",
      "Epoch 23 of 50\n",
      "Train Loss: -2.0583\n",
      "Val Loss: -2.0829\n",
      "Epoch 24 of 50\n",
      "Train Loss: -2.0584\n",
      "Val Loss: -2.0782\n",
      "Epoch 25 of 50\n",
      "Train Loss: -2.0587\n",
      "Val Loss: -2.0799\n",
      "Epoch 26 of 50\n",
      "Train Loss: -2.0587\n",
      "Val Loss: -2.0814\n",
      "Epoch 27 of 50\n",
      "Train Loss: -2.0585\n",
      "Val Loss: -2.0802\n",
      "Epoch 28 of 50\n",
      "Train Loss: -2.0588\n",
      "Val Loss: -2.0820\n",
      "Epoch 29 of 50\n",
      "Train Loss: -2.0587\n",
      "Val Loss: -2.0802\n",
      "Epoch 30 of 50\n",
      "Train Loss: -2.0588\n",
      "Val Loss: -2.0804\n",
      "Epoch 31 of 50\n",
      "Train Loss: -2.0589\n",
      "Val Loss: -2.0780\n",
      "Epoch 32 of 50\n",
      "Train Loss: -2.0585\n",
      "Val Loss: -2.0805\n",
      "Epoch 33 of 50\n",
      "Train Loss: -2.0582\n",
      "Val Loss: -2.0801\n",
      "Epoch 34 of 50\n",
      "Train Loss: -2.0589\n",
      "Val Loss: -2.0804\n",
      "Epoch 35 of 50\n",
      "Train Loss: -2.0590\n",
      "Val Loss: -2.0801\n",
      "Epoch 36 of 50\n",
      "Train Loss: -2.0590\n",
      "Val Loss: -2.0822\n",
      "Epoch 37 of 50\n",
      "Train Loss: -2.0587\n",
      "Val Loss: -2.0810\n",
      "Epoch 38 of 50\n",
      "Train Loss: -2.0588\n",
      "Val Loss: -2.0810\n",
      "Epoch 39 of 50\n",
      "Train Loss: -2.0590\n",
      "Val Loss: -2.0804\n",
      "Epoch 40 of 50\n",
      "Train Loss: -2.0587\n",
      "Val Loss: -2.0799\n",
      "Epoch 41 of 50\n",
      "Train Loss: -2.0584\n",
      "Val Loss: -2.0782\n",
      "Epoch 42 of 50\n",
      "Train Loss: -2.0585\n",
      "Val Loss: -2.0798\n",
      "Epoch 43 of 50\n",
      "Train Loss: -2.0587\n",
      "Val Loss: -2.0780\n",
      "Epoch 44 of 50\n",
      "Train Loss: -2.0588\n",
      "Val Loss: -2.0804\n",
      "Epoch 45 of 50\n",
      "Train Loss: -2.0586\n",
      "Val Loss: -2.0823\n",
      "Epoch 46 of 50\n",
      "Train Loss: -2.0582\n",
      "Val Loss: -2.0797\n",
      "Epoch 47 of 50\n",
      "Train Loss: -2.0585\n",
      "Val Loss: -2.0790\n",
      "Epoch 48 of 50\n",
      "Train Loss: -2.0581\n",
      "Val Loss: -2.0824\n",
      "Epoch 49 of 50\n",
      "Train Loss: -2.0580\n",
      "Val Loss: -2.0796\n",
      "Epoch 50 of 50\n",
      "Train Loss: -2.0583\n",
      "Val Loss: -2.0791\n"
     ]
    }
   ],
   "source": [
    "#MNIST\n",
    "net = VAE(D = 28*28*1, M = 16)\n",
    "# net = VAE(D = 32*32*3, M = 16)\n",
    "net.to(device)\n",
    "optimizer = optim.Adam(net.parameters(), lr = 0.005)\n",
    "net, train_loss, val_loss= train(net, trainloader, valiloader, optimizer, 50 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "467613a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-1.9352454650878905,\n",
       " -1.983359812927246,\n",
       " -2.016566542053223,\n",
       " -2.047689262390137,\n",
       " -2.058992478942871,\n",
       " -2.066827844238281,\n",
       " -2.069573812866211,\n",
       " -2.071612649536133,\n",
       " -2.074682974243164,\n",
       " -2.0734833557128907,\n",
       " -2.0750765380859373,\n",
       " -2.0760799865722657,\n",
       " -2.0772979888916017,\n",
       " -2.0753298553466797,\n",
       " -2.0778515838623046,\n",
       " -2.0776038970947264,\n",
       " -2.0786314392089844,\n",
       " -2.078510565185547,\n",
       " -2.0791779006958007,\n",
       " -2.0772095520019533,\n",
       " -2.0757425201416018,\n",
       " -2.081010192871094,\n",
       " -2.0829079223632814,\n",
       " -2.078243975830078,\n",
       " -2.079880960083008,\n",
       " -2.0813811431884766,\n",
       " -2.080195248413086,\n",
       " -2.0820124420166017,\n",
       " -2.0801575805664063,\n",
       " -2.0804015014648436,\n",
       " -2.0779665969848633,\n",
       " -2.0805175048828124,\n",
       " -2.080138983154297,\n",
       " -2.080396682739258,\n",
       " -2.0800753936767578,\n",
       " -2.0822245544433593,\n",
       " -2.080994616699219,\n",
       " -2.0809822021484377,\n",
       " -2.0804029541015625,\n",
       " -2.0799052307128907,\n",
       " -2.078240316772461,\n",
       " -2.0797628295898436,\n",
       " -2.0780477447509766,\n",
       " -2.08035498046875,\n",
       " -2.082277133178711,\n",
       " -2.079669839477539,\n",
       " -2.079001593017578,\n",
       " -2.0824281799316404,\n",
       " -2.0796427307128904,\n",
       " -2.079116226196289]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#values to plot\n",
    "val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45a1df8",
   "metadata": {},
   "source": [
    "# SVHN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be7c3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "transform2 = transforms.Compose([transforms.Resize((28, 28)),transforms.ToTensor(),transforms.Normalize((0.5,), (0.5,))]) \n",
    "\n",
    "#load in full train set\n",
    "trainsetfull2 = torchvision.datasets.SVHN(root='./data/svhn', split='train', download=True, transform=transform2)\n",
    "print(len(trainsetfull2))\n",
    "\n",
    "# data loader for final run \n",
    "trainfullloader2 = torch.utils.data.DataLoader(trainsetfull2, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "#split the set \n",
    "trainset2, valset2 = torch.utils.data.random_split(trainsetfull2, [65000,8257])\n",
    "#load in test set\n",
    "testset2 = torchvision.datasets.SVHN(root='./data/svhn', split='test', transform=transform2,download=True)\n",
    "\n",
    "\n",
    "# data loader for training\n",
    "trainloader2 = torch.utils.data.DataLoader(trainset2, batch_size=BATCH_SIZE,shuffle=True, num_workers=2)\n",
    "# data loader for validation\n",
    "valiloader2 = torch.utils.data.DataLoader(valset2, batch_size=BATCH_SIZE,shuffle=True, num_workers=2)\n",
    "# data loader for testing\n",
    "testloader2 = torch.utils.data.DataLoader(testset2, batch_size=BATCH_SIZE,shuffle=False, num_workers=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
