{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in /opt/anaconda3/lib/python3.9/site-packages (0.11.1)\n",
      "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /opt/anaconda3/lib/python3.9/site-packages (from torchvision) (8.4.0)\n",
      "Requirement already satisfied: torch==1.10.0 in /opt/anaconda3/lib/python3.9/site-packages (from torchvision) (1.10.0)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.9/site-packages (from torchvision) (1.21.4)\n",
      "Requirement already satisfied: typing-extensions in /opt/anaconda3/lib/python3.9/site-packages (from torch==1.10.0->torchvision) (4.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: matplotlib in /opt/anaconda3/lib/python3.9/site-packages (3.5.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/anaconda3/lib/python3.9/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/anaconda3/lib/python3.9/site-packages (from matplotlib) (8.4.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.9/site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: setuptools-scm>=4 in /opt/anaconda3/lib/python3.9/site-packages (from matplotlib) (6.3.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/lib/python3.9/site-packages (from matplotlib) (1.21.4)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/lib/python3.9/site-packages (from matplotlib) (4.28.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/anaconda3/lib/python3.9/site-packages (from matplotlib) (3.0.4)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/lib/python3.9/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/anaconda3/lib/python3.9/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.9/site-packages (from setuptools-scm>=4->matplotlib) (58.0.4)\n",
      "Requirement already satisfied: tomli>=1.0.0 in /opt/anaconda3/lib/python3.9/site-packages (from setuptools-scm>=4->matplotlib) (1.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.9/site-packages (1.7.3)\n",
      "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /opt/anaconda3/lib/python3.9/site-packages (from scipy) (1.21.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: sklearn in /opt/anaconda3/lib/python3.9/site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/lib/python3.9/site-packages (from sklearn) (1.0.1)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /opt/anaconda3/lib/python3.9/site-packages (from scikit-learn->sklearn) (1.7.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/anaconda3/lib/python3.9/site-packages (from scikit-learn->sklearn) (3.0.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/anaconda3/lib/python3.9/site-packages (from scikit-learn->sklearn) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.14.6 in /opt/anaconda3/lib/python3.9/site-packages (from scikit-learn->sklearn) (1.21.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torchvision\n",
    "%pip install matplotlib\n",
    "%pip install scipy\n",
    "%pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "TOyGrPT5ASDc"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "import os\n",
    "import scipy\n",
    "from torchvision import datasets, transforms\n",
    "from torch import optim, nn, unsqueeze\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor, Lambda, Compose\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "id": "sZD2NGz2Ak6w",
    "outputId": "fc274df4-7663-4f35-d490-92f4bbcd3e49"
   },
   "outputs": [],
   "source": [
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.Resize((28,28)), transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# with data augmentation for training only\n",
    "train_transform = transforms.Compose([transforms.Resize((28,28)), transforms.ToTensor(),\n",
    "                                    # transforms.ToPILImage(),\n",
    "                                    # transforms.CenterCrop(21),\n",
    "                                    transforms.RandomRotation(30),\n",
    "                                    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "                                    # transforms.RandomAffine(degrees=20, translate=(0.1,0.1), scale=(0.9, 1.1)),\n",
    "                                    transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# Download and load the training data\n",
    "trainset0 = datasets.ImageFolder('/Users/enrico/Downloads/mnist-varres/train', transform=train_transform)\n",
    "testset = datasets.ImageFolder('/Users/enrico/Downloads/mnist-varres/test', transform=transform)\n",
    "\n",
    "# Also create a validation set \n",
    "trainset, valset = train_test_split(trainset0, test_size=10000, random_state=42)\n",
    "#pytorch alternative for spliting into train and validation sets\n",
    "#https://stackoverflow.com/questions/50544730/how-do-i-split-a-custom-dataset-into-training-and-test-datasets\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([16, 3, 28, 28])\n",
      "torch.Size([16])\n"
     ]
    }
   ],
   "source": [
    "training_data = enumerate(trainloader)\n",
    "batch_idx, (images, labels) = next(training_data)\n",
    "print(type(images)) # Checking the datatype \n",
    "print(images.shape) # the size of the image\n",
    "print(labels.shape) # the size of the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "XCsoAdjdLjPb"
   },
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "\n",
    "        self.conv_neural_network_layers = nn.Sequential(\n",
    "                # output_sizeOfEachConvLayer = [(in_channel + 2*padding - kernel_size) / stride] + 1\n",
    "\n",
    "                # We have in_channels=1 because our input is a grayscale image\n",
    "                nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1, stride=1), # (N, 1, 28, 28) \n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(kernel_size=2), \n",
    "\n",
    "                # output of second conv layer\n",
    "                nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1, stride=1),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(kernel_size=2), \n",
    "\n",
    "                # output of third conv layer\n",
    "                nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1, stride=1),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(kernel_size=2) )\n",
    "\n",
    "        # Linear layer\n",
    "        self.linear_layers = nn.Sequential(\n",
    "                nn.Linear(64*3*3, 10))\n",
    "                # nn.Linear(16, 10)) # The output is 10 which should match the size of our class\n",
    "\n",
    "\n",
    "    # Defining the forward pass \n",
    "    def forward(self, x):\n",
    "        x = self.conv_neural_network_layers(x)\n",
    "        # After we get the output of our convolutional layer we must flatten it or rearrange the output into a vector\n",
    "        x = torch.flatten(x, 1) # same as x = x.view(x.size(0), -1)\n",
    "        # Then pass it through the linear layer\n",
    "        x = self.linear_layers(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "model = Network()\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "loss_fn = nn.BCEWithLogitsLoss() #nn.BCELoss() \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "#In a single training loop, the model makes predictions on the training dataset (fed to it in batches), and backpropagates the prediction error to adjust the model’s parameters.\n",
    "\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        y_hot = F.one_hot(y, 10)\n",
    "        y_hot = torch.zeros(batch_size, 10)\n",
    "        y_hot[range(y_hot.shape[0]), y]=1      \n",
    "\n",
    "        X, y_hot = X.to(device), y_hot.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y_hot)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            # print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "    return loss\n",
    "\n",
    "#We also check the model’s performance against the test dataset to ensure it is learning.\n",
    "\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        y_hot = F.one_hot(y, 10)\n",
    "        y_hot = torch.zeros(batch_size, 10)\n",
    "        y_hot[range(y_hot.shape[0]), y]=1      \n",
    "\n",
    "        X, y_hot = X.to(device), y_hot.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        test_loss += loss_fn(pred, y_hot).item()\n",
    "        correct += (pred.argmax(axis=1) == y_hot.argmax(axis=1)).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= 10000\n",
    "    correct /= size\n",
    "\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    return test_loss, 100*correct\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mlcZpCvSjdf1"
   },
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 819
    },
    "id": "qHdCWNiZzyxA",
    "outputId": "9b50f98d-f34b-41bc-842d-9c3fafc0b9af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 84.9%, Avg loss: 0.005715 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 89.7%, Avg loss: 0.004145 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 91.0%, Avg loss: 0.003587 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.003717 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 92.5%, Avg loss: 0.003309 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 92.7%, Avg loss: 0.003179 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 92.9%, Avg loss: 0.003098 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.4%, Avg loss: 0.003077 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.003149 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.5%, Avg loss: 0.002967 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.8%, Avg loss: 0.003068 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.3%, Avg loss: 0.003141 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.5%, Avg loss: 0.003175 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.3%, Avg loss: 0.003241 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.6%, Avg loss: 0.003212 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.2%, Avg loss: 0.003422 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.5%, Avg loss: 0.003330 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.4%, Avg loss: 0.003402 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.6%, Avg loss: 0.003524 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.2%, Avg loss: 0.003834 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "\n",
    "mmp_train_loss = []\n",
    "mmp_loss = []\n",
    "mmp_acc = []\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loss = train(trainloader, model, loss_fn, optimizer)\n",
    "    mmp_train_loss.append(train_loss)\n",
    "    loss, acc = test(valloader, model, loss_fn)\n",
    "    mmp_loss.append(loss)\n",
    "    mmp_acc.append(acc)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "handwritten_digit_recognition_CPU.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}